"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
current_file = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file)))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.utils.config import OUTPUT_DIR
from src.utils.logging import log_info
from src.utils.encoding_handler import save_csv_with_encoding, save_text_with_encoding



def save_results(results, product, timestamp=None, session_id=None, write_to_hubspot_criteria=False, original_file_path=None):
    """Save results to both JSON and CSV files in session-specific directory"""
    if not timestamp:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ü–ê–†–ê–ú–ï–¢–†–û–í
    log_info(f"üîß save_results –≤—ã–∑–≤–∞–Ω–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:")
    log_info(f"   üìä results: {len(results)} –∑–∞–ø–∏—Å–µ–π")
    log_info(f"   üì¶ product: {product}")
    log_info(f"   üïí timestamp: {timestamp}")
    log_info(f"   üÜî session_id: {session_id}")
    log_info(f"   üîó write_to_hubspot_criteria: {write_to_hubspot_criteria}")
    log_info(f"   üìÑ original_file_path: {original_file_path}")
    
    # Create session-specific output directory
    if session_id:
        session_output_dir = os.path.join(OUTPUT_DIR, session_id)
        log_info(f"üìÅ –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É —Å–µ—Å—Å–∏–∏: {session_output_dir}")
    else:
        session_output_dir = OUTPUT_DIR
        log_info(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –ø–∞–ø–∫—É: {session_output_dir}")
    
    # Ensure session output directory exists
    os.makedirs(session_output_dir, exist_ok=True)
    
    # Create output filenames
    json_filename = f"analysis_results_{product}_{timestamp}.json"
    csv_filename = f"analysis_results_{product}_{timestamp}.csv"
    
    json_path = os.path.join(session_output_dir, json_filename)
    csv_path = os.path.join(session_output_dir, csv_filename)
    
    # Save to JSON with pretty formatting using UTF-8
    json_content = json.dumps(results, ensure_ascii=False, indent=2)
    save_text_with_encoding(json_content, json_path, encoding='utf-8')
    log_info(f"üíæ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {json_path}")
    
    # Convert to CSV format
    csv_data = []
    for result in results:
        # Flatten nested structures for CSV
        flat_result = flatten_result_for_csv(result)
        csv_data.append(flat_result)
    
    # Save to CSV with proper encoding handling
    if csv_data:
        df = pd.DataFrame(csv_data)
        save_csv_with_encoding(df, csv_path, encoding='utf-8-sig')
        
        log_info(f"üíæ CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {csv_path}")
        log_info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}")
        log_info(f"üìã –ö–æ–ª–æ–Ω–æ–∫ –≤ CSV: {len(df.columns) if not df.empty else 0}")
    
    # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï HUBSPOT –ò–ù–¢–ï–ì–†–ê–¶–ò–ò
    log_info(f"üîç –ü–†–û–í–ï–†–ö–ê HUBSPOT –ò–ù–¢–ï–ì–†–ê–¶–ò–ò:")
    log_info(f"   üîó write_to_hubspot_criteria = {write_to_hubspot_criteria}")
    log_info(f"   üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ = {len(results)}")
    
    # HubSpot Integration for Criteria - –ü–†–û–°–¢–ê–Ø –í–ï–†–°–ò–Ø –ö–ê–ö –í –ü–ï–†–í–û–ô –í–ö–õ–ê–î–ö–ï
    if write_to_hubspot_criteria:
        log_info("üöÄ HUBSPOT –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –í–ö–õ–Æ–ß–ï–ù–ê - –Ω–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        
        try:
            log_info("üîó –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å HubSpot –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
            hubspot_api_key = os.getenv("HUBSPOT_API_KEY")
            log_info(f"üîë –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞: {'–ù–ê–ô–î–ï–ù' if hubspot_api_key else '–ù–ï –ù–ê–ô–î–ï–ù'}")
            if hubspot_api_key:
                log_info(f"üîë API –∫–ª—é—á –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å: {hubspot_api_key[:10]}...")
            
            if not hubspot_api_key:
                log_info("‚ö†Ô∏è HUBSPOT_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é")
                return json_path, csv_path
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º HubSpot –∫–ª–∏–µ–Ω—Ç –Ω–∞–ø—Ä—è–º—É—é
            log_info("üì¶ –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º HubSpot –∫–ª–∏–µ–Ω—Ç...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ src.integrations
            if project_root not in sys.path:
                sys.path.insert(0, project_root)
                log_info(f"üìÅ –î–æ–±–∞–≤–ª–µ–Ω –ø—É—Ç—å –≤ sys.path: {project_root}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—É—Ç—å –∫ HubSpot –∫–ª–∏–µ–Ω—Ç—É —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            hubspot_client_path = os.path.join(project_root, "src", "integrations", "hubspot", "client.py")
            log_info(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å –∫ HubSpot –∫–ª–∏–µ–Ω—Ç—É: {hubspot_client_path}")
            log_info(f"üìÑ –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {os.path.exists(hubspot_client_path)}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º importlib –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
            import importlib.util
            spec = importlib.util.spec_from_file_location("hubspot_client", hubspot_client_path)
            hubspot_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(hubspot_module)
            HubSpotClient = hubspot_module.HubSpotClient
            log_info("‚úÖ HubSpot –∫–ª–∏–µ–Ω—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ importlib")
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
            log_info("üîß –°–æ–∑–¥–∞–µ–º HubSpot –∫–ª–∏–µ–Ω—Ç...")
            hubspot_client = HubSpotClient(api_key=hubspot_api_key)
            log_info("‚úÖ HubSpot –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            stats = {"processed": 0, "updated": 0, "errors": 0, "skipped": 0}
            
            log_info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(results)} –∫–æ–º–ø–∞–Ω–∏–π...")
            
            for i, result in enumerate(results):
                try:
                    company_name = result.get("Company_Name", "")
                    hubspot_company_id = result.get("HubSpot_Company_ID")
                    
                    log_info(f"üè¢ [{i+1}/{len(results)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {company_name}")
                    log_info(f"   üÜî HubSpot_Company_ID: {hubspot_company_id}")
                    
                    if not company_name or not hubspot_company_id:
                        log_info(f"   ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º - –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç Company_Name –∏–ª–∏ HubSpot_Company_ID")
                        stats["skipped"] += 1
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    original_id = hubspot_company_id
                    if isinstance(hubspot_company_id, str) and "hubspot.com" in hubspot_company_id:
                        hubspot_company_id = hubspot_company_id.split("/")[-1]
                        log_info(f"   üîó –ò–∑–≤–ª–µ—á–µ–Ω ID {hubspot_company_id} –∏–∑ URL {original_id}")
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ - –¢–û–õ–¨–ö–û ai_criteria
                    criteria_data = result.get("All_Results", {})
                    log_info(f"   üìä All_Results —Å–æ–¥–µ—Ä–∂–∏—Ç {len(criteria_data)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {list(criteria_data.keys())}")
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                    criteria_json = json.dumps(criteria_data, ensure_ascii=False, separators=(',', ':'))
                    update_data = {
                        "ai_criteria": criteria_json
                    }
                    log_info(f"   üìù –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏: ai_criteria ({len(criteria_json)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–º–ø–∞–Ω–∏—é –≤ HubSpot —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                    log_info(f"   üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ HubSpot –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ ID {hubspot_company_id}...")
                    import asyncio
                    
                    # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –∑–∞–ø—É—Å–∫–∞ async —Ñ—É–Ω–∫—Ü–∏–∏
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        success = loop.run_until_complete(
                            hubspot_client.update_company_properties(hubspot_company_id, update_data)
                        )
                        log_info(f"   üì° HubSpot API –≤–µ—Ä–Ω—É–ª: {success}")
                    finally:
                        loop.close()
                    
                    if success:
                        log_info(f"   ‚úÖ {company_name}: –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ HubSpot")
                        stats["updated"] += 1
                    else:
                        log_info(f"   ‚ùå {company_name}: –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ HubSpot")
                        stats["errors"] += 1
                    
                    stats["processed"] += 1
                    
                except Exception as e:
                    log_info(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {company_name}: {e}")
                    import traceback
                    log_info(f"   üìã Traceback: {traceback.format_exc()}")
                    stats["errors"] += 1
            
            log_info(f"üéâ HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            log_info(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}")
            log_info(f"   ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['updated']}")
            log_info(f"   ‚ùå –û—à–∏–±–æ–∫: {stats['errors']}")
            log_info(f"   ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
            
        except Exception as e:
            log_info(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
            import traceback
            log_info(f"üìã –ü–æ–ª–Ω—ã–π traceback: {traceback.format_exc()}")
    else:
        log_info("üìù HUBSPOT –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –û–¢–ö–õ–Æ–ß–ï–ù–ê (write_to_hubspot_criteria=False)")
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    if original_file_path and os.path.exists(original_file_path):
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
            sys.path.insert(0, project_root)
            from src.data_io import merge_original_with_results
            
            # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            merged_file_path = csv_path.replace('.csv', '_merged.csv')
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            merge_success = merge_original_with_results(
                original_file_path=original_file_path,
                results_file_path=csv_path,
                output_file_path=merged_file_path
            )
            
            if merge_success:
                log_info(f"üìã –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {merged_file_path}")
                # –ó–∞–º–µ–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º
                import shutil
                shutil.move(merged_file_path, csv_path)
                log_info(f"üìã –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–º–µ–Ω–µ–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º: {csv_path}")
            else:
                log_info("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
        except Exception as e:
            log_info(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤: {e}")
            log_info("‚ö†Ô∏è –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
    else:
        if original_file_path:
            log_info(f"‚ö†Ô∏è –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_file_path}")
        else:
            log_info("üìù –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ")
    
    return json_path, csv_path

def flatten_result_for_csv(result):
    """Converts result to flat dictionary for CSV - CLEAN VERSION"""
    flat = {}
    
    # –ö–æ–ø–∏—Ä—É–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏
    for key, value in result.items():
        if key == "Qualified_Products":
            # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º json.dumps –¥–ª—è —ç—Ç–æ–π –∫–æ–ª–æ–Ω–∫–∏! –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∫–∞–∫ –µ—Å—Ç—å
            flat[key] = value if value else ""
        elif key == "All_Results":
            # JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            flat[key] = json.dumps(value, ensure_ascii=False, indent=2) if value else ""
        else:
            # –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            if isinstance(value, (dict, list)):
                flat[key] = json.dumps(value, ensure_ascii=False, indent=2) if value else ""
            else:
                flat[key] = value
    
    return flat 