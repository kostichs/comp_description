"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
current_file = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file)))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.utils.config import OUTPUT_DIR
from src.utils.logging import log_info
from src.utils.encoding_handler import save_csv_with_encoding, save_text_with_encoding

def save_results(results, product, timestamp=None, session_id=None, write_to_hubspot_criteria=False, original_file_path=None):
    """Save results to both JSON and CSV files in session-specific directory"""
    if not timestamp:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Create session-specific output directory
    if session_id:
        session_output_dir = os.path.join(OUTPUT_DIR, session_id)
        log_info(f"üìÅ –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É —Å–µ—Å—Å–∏–∏: {session_output_dir}")
    else:
        session_output_dir = OUTPUT_DIR
        log_info(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –ø–∞–ø–∫—É: {session_output_dir}")
    
    # Ensure session output directory exists
    os.makedirs(session_output_dir, exist_ok=True)
    
    # Create output filenames
    json_filename = f"analysis_results_{product}_{timestamp}.json"
    csv_filename = f"analysis_results_{product}_{timestamp}.csv"
    
    json_path = os.path.join(session_output_dir, json_filename)
    csv_path = os.path.join(session_output_dir, csv_filename)
    
    # Save to JSON with pretty formatting using UTF-8
    json_content = json.dumps(results, ensure_ascii=False, indent=2)
    save_text_with_encoding(json_content, json_path, encoding='utf-8')
    log_info(f"üíæ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {json_path}")
    
    # Convert to CSV format
    csv_data = []
    for result in results:
        # Flatten nested structures for CSV
        flat_result = flatten_result_for_csv(result)
        csv_data.append(flat_result)
    
    # Save to CSV with proper encoding handling
    if csv_data:
        df = pd.DataFrame(csv_data)
        save_csv_with_encoding(df, csv_path, encoding='utf-8-sig')
        
        log_info(f"üíæ CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {csv_path}")
        log_info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}")
        log_info(f"üìã –ö–æ–ª–æ–Ω–æ–∫ –≤ CSV: {len(df.columns) if not df.empty else 0}")
    
    # HubSpot Integration for Criteria
    if write_to_hubspot_criteria:
        try:
            log_info("üîó –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å HubSpot –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤...")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é HubSpot –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É
            hubspot_api_key = os.getenv("HUBSPOT_API_KEY")
            if not hubspot_api_key:
                log_info("‚ö†Ô∏è HUBSPOT_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é")
                return json_path, csv_path
            
            # –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç HubSpot –∫–ª–∏–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ spec
            import importlib.util
            client_path = os.path.join(project_root, "src", "integrations", "hubspot", "client.py")
            spec = importlib.util.spec_from_file_location("hubspot_client", client_path)
            client_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(client_module)
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            hubspot_client = client_module.HubSpotClient()
            
            stats = {"processed": 0, "updated": 0, "errors": 0, "skipped": 0}
            
            for result in results:
                try:
                    company_name = result.get("Company_Name", "")
                    hubspot_company_id = result.get("HubSpot_Company_ID")
                    
                    if not company_name or not hubspot_company_id:
                        stats["skipped"] += 1
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if isinstance(hubspot_company_id, str) and "hubspot.com" in hubspot_company_id:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL —Ç–∏–ø–∞ https://app.hubspot.com/contacts/4202168/record/0-2/4833748489
                        hubspot_company_id = hubspot_company_id.split("/")[-1]
                        log_info(f"üîó {company_name}: –∏–∑–≤–ª–µ—á–µ–Ω ID {hubspot_company_id} –∏–∑ URL")
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏
                    criteria_data = result.get("All_Results", {})
                    description = result.get("Description", "")
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                    update_data = {
                        "ai_criteria": json.dumps(criteria_data, ensure_ascii=False, separators=(',', ':')),
                        "ai_description": description,
                        "ai_description_updated": datetime.now().isoformat()
                    }
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–º–ø–∞–Ω–∏—é –≤ HubSpot —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                    import asyncio
                    import concurrent.futures
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è async —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
                    def run_async_in_thread():
                        return asyncio.run(hubspot_client.update_company_properties(hubspot_company_id, update_data))
                    
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(run_async_in_thread)
                        success = future.result()
                    
                    if success:
                        log_info(f"‚úÖ {company_name}: –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ HubSpot")
                        stats["updated"] += 1
                    else:
                        log_info(f"‚ùå {company_name}: –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ HubSpot")
                        stats["errors"] += 1
                    
                    stats["processed"] += 1
                    
                except Exception as e:
                    log_info(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {company_name}: {e}")
                    stats["errors"] += 1
            
            log_info(f"‚úÖ HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats}")
            
        except ImportError as e:
            log_info(f"‚ö†Ô∏è HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –º–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        except Exception as e:
            log_info(f"‚ùå –û—à–∏–±–∫–∞ HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
    else:
        log_info("üìù HubSpot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    if original_file_path and os.path.exists(original_file_path):
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
            sys.path.insert(0, project_root)
            from src.data_io import merge_original_with_results
            
            # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            merged_file_path = csv_path.replace('.csv', '_merged.csv')
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            merge_success = merge_original_with_results(
                original_file_path=original_file_path,
                results_file_path=csv_path,
                output_file_path=merged_file_path
            )
            
            if merge_success:
                log_info(f"üìã –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {merged_file_path}")
                # –ó–∞–º–µ–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º
                import shutil
                shutil.move(merged_file_path, csv_path)
                log_info(f"üìã –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–º–µ–Ω–µ–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º: {csv_path}")
            else:
                log_info("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
        except Exception as e:
            log_info(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤: {e}")
            log_info("‚ö†Ô∏è –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
    else:
        if original_file_path:
            log_info(f"‚ö†Ô∏è –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_file_path}")
        else:
            log_info("üìù –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ")
    
    return json_path, csv_path

def flatten_result_for_csv(result):
    """Converts result to flat dictionary for CSV - CLEAN VERSION"""
    flat = {}
    
    # –ö–æ–ø–∏—Ä—É–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏
    for key, value in result.items():
        if key == "Qualified_Products":
            # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º json.dumps –¥–ª—è —ç—Ç–æ–π –∫–æ–ª–æ–Ω–∫–∏! –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∫–∞–∫ –µ—Å—Ç—å
            flat[key] = value if value else ""
        elif key == "All_Results":
            # JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            flat[key] = json.dumps(value, ensure_ascii=False, indent=2) if value else ""
        else:
            # –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            if isinstance(value, (dict, list)):
                flat[key] = json.dumps(value, ensure_ascii=False, indent=2) if value else ""
            else:
                flat[key] = value
    
    return flat 