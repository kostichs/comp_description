import time
import logging
from fastapi import HTTPException
from fastapi import APIRouter
from src.data_io import load_session_metadata, save_session_metadata, SESSIONS_DIR, SESSIONS_METADATA_FILE

logger = logging.getLogger(__name__)

router = APIRouter()

@router.get("/sessions")
async def get_sessions():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Å–µ—Å—Å–∏–π"""
    try:
        logger.info("GET /api/sessions - –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ get_sessions –∏–∑ —Ä–æ—É—Ç–µ—Ä–∞ sessions.py")
        metadata = load_session_metadata()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å–µ—Å—Å–∏–∏, –ø–∞–ø–∫–∏ –∫–æ—Ç–æ—Ä—ã—Ö —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –∏–º–µ—é—Ç —Å—Ç–∞—Ç—É—Å completed
        import os
        filtered_sessions = []
        for session in metadata:
            session_id = session.get("session_id")
            session_dir = SESSIONS_DIR / session_id  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ —Å–µ—Å—Å–∏–∏ –∏ —Å—Ç–∞—Ç—É—Å completed
            if session_dir.exists() and session.get("status") == "completed":
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª–µ created_time –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ä–æ–µ –ø–æ–ª–µ timestamp_created
                if "created_time" not in session and "timestamp_created" in session:
                    session["created_time"] = session["timestamp_created"]
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å –ø–æ–ª–µ total_companies
                if "total_companies" not in session:
                    session["total_companies"] = session.get("companies_count", 0)
                
                filtered_sessions.append(session)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è, –Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É
        filtered_sessions.sort(key=lambda x: x.get("created_time", ""), reverse=True)
        
        logger.info(f"Filtered {len(filtered_sessions)} valid sessions out of {len(metadata)} total")
        return filtered_sessions
    except Exception as e:
        logger.error(f"Error getting sessions: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/sessions/{session_id}")
async def get_session(session_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–µ—Å—Å–∏–∏ –ø–æ ID"""
    try:
        logger.info(f"GET /api/sessions/{session_id} - –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ get_session –∏–∑ —Ä–æ—É—Ç–µ—Ä–∞ sessions.py")
        metadata = load_session_metadata()
        session_data = next((m for m in metadata if m.get("session_id") == session_id), None)
        
        if not session_data:
            logger.error(f"Session {session_id} not found")
            raise HTTPException(status_code=404, detail=f"Session {session_id} not found")
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç)
        dedup_info = session_data.get("deduplication_info")
        if dedup_info and isinstance(dedup_info.get("final_count"), int) and dedup_info.get("duplicates_removed", 0) > 0:
            original = dedup_info.get("original_count", 0)
            removed = dedup_info.get("duplicates_removed", 0)
            final = dedup_info.get("final_count", 0)
            
            dedup_message_text = f"Removed {removed} duplicates"
            
            processing_messages = session_data.get("processing_messages", [])
            has_dedup_message = any(msg.get("type") == "deduplication" and msg.get("message") == dedup_message_text for msg in processing_messages)
            
            if not has_dedup_message:
                new_message = {
                    "type": "deduplication",
                    "message": dedup_message_text,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                }
                session_data["processing_messages"] = processing_messages + [new_message]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, —Ç–∞–∫ –∫–∞–∫ –¥–æ–±–∞–≤–∏–ª–∏ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                current_all_metadata = load_session_metadata() 
                updated_all_metadata = []
                for meta_item in current_all_metadata:
                    if meta_item.get("session_id") == session_id:
                        updated_all_metadata.append(session_data) 
                    else:
                        updated_all_metadata.append(meta_item)
                save_session_metadata(updated_all_metadata)
                logger.info(f"Session {session_id}: –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏.")
        
        return session_data
    except Exception as e:
        logger.error(f"Error getting session {session_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/sessions/{session_id}/results_file")
async def get_session_results_file(session_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–º—É —Ñ–∞–π–ª—É —Å–µ—Å—Å–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ criteria analysis"""
    try:
        logger.info(f"GET /api/sessions/{session_id}/results_file - –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–º—É —Ñ–∞–π–ª—É")
        metadata = load_session_metadata()
        session_data = next((m for m in metadata if m.get("session_id") == session_id), None)
        
        if not session_data:
            logger.error(f"Session {session_id} not found")
            raise HTTPException(status_code=404, detail=f"Session {session_id} not found")
        
        if session_data.get("status") != "completed":
            raise HTTPException(status_code=400, detail=f"Session {session_id} is not completed yet")
        
        # –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–º—É —Ñ–∞–π–ª—É (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π)
        results_file_path = SESSIONS_DIR / session_id / f"{session_id}_results.csv"
        
        return {
            "session_id": session_id,
            "file_path": str(results_file_path),  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
            "status": session_data.get("status"),
            "total_companies": session_data.get("total_companies", 0),
            "created_time": session_data.get("created_time", "")
        }
    except Exception as e:
        logger.error(f"Error getting results file for session {session_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

def cleanup_old_sessions(max_sessions: int = 10) -> None:
    """
    –û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Å–µ—Å—Å–∏–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö
    
    Args:
        max_sessions: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Å—Å–∏–π –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    try:
        logger.info(f"üßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É —Å—Ç–∞—Ä—ã—Ö —Å–µ—Å—Å–∏–π (–æ—Å—Ç–∞–≤–ª—è–µ–º {max_sessions})")
        metadata = load_session_metadata()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ completed —Å–µ—Å—Å–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞–ø–∫–∞–º–∏
        valid_sessions = []
        for session in metadata:
            session_id = session.get("session_id")
            session_dir = SESSIONS_DIR / session_id
            
            if session_dir.exists() and session.get("status") == "completed":
                # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å –ø–æ–ª–µ created_time
                if "created_time" not in session and "timestamp_created" in session:
                    session["created_time"] = session["timestamp_created"]
                valid_sessions.append(session)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        valid_sessions.sort(key=lambda x: x.get("created_time", ""), reverse=True)
        
        # –ï—Å–ª–∏ —Å–µ—Å—Å–∏–π –±–æ–ª—å—à–µ –º–∞–∫—Å–∏–º—É–º–∞, —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ
        if len(valid_sessions) > max_sessions:
            sessions_to_remove = valid_sessions[max_sessions:]
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(sessions_to_remove)} —Å–µ—Å—Å–∏–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
            
            import shutil
            for session in sessions_to_remove:
                session_id = session.get("session_id")
                session_dir = SESSIONS_DIR / session_id
                
                # –£–¥–∞–ª—è–µ–º –ø–∞–ø–∫—É —Å–µ—Å—Å–∏–∏
                if session_dir.exists():
                    shutil.rmtree(session_dir)
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø–∞–ø–∫–∞ —Å–µ—Å—Å–∏–∏: {session_id}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–µ—Å—Å–∏–∏
            updated_metadata = [s for s in metadata if s.get("session_id") not in 
                              [old_s.get("session_id") for old_s in sessions_to_remove]]
            save_session_metadata(updated_metadata)
            logger.info(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(updated_metadata)} —Å–µ—Å—Å–∏–π")
        else:
            logger.info(f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π ({len(valid_sessions)}) <= {max_sessions}")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö —Å–µ—Å—Å–∏–π: {e}", exc_info=True) 